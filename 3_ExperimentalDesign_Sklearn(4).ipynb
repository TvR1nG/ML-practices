{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_ExperimentalDesign_Sklearn(4).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PG7F15TeVuxb","colab_type":"text"},"source":["This Jupyter notebook includes exercises for understanding experimental design in Machine Learning. In this notebook we will introduce common evaluation measures in supervised machine learning. You will also be able to split your dataset in train, development and test, and also understand how cross-validation works. \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oXTVxIXysM9O","colab_type":"text"},"source":["## EXPERIMENTAL DESIGN\n","\n","---\n","\n","First, we import the libraries that we are going to use, including as usual numpy (vector manipulation), nltk (text preprocessing) and scikit-learn (machine learning).\n","\n","**Note:** All these libraries need to be downloaded beforehand if not using Google Colab. Check their official websites for details on how to install them."]},{"cell_type":"code","metadata":{"id":"-Nv6UldrVuXv","colab_type":"code","outputId":"8b016290-5768-4117-9fe9-3911aedfb078","executionInfo":{"status":"ok","timestamp":1578154197282,"user_tz":0,"elapsed":3689,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["import numpy as np\n","import nltk\n","import sklearn\n","import operator\n","import requests\n","nltk.download('stopwords') # If needed\n","nltk.download('punkt') # If needed\n","nltk.download('wordnet') # If needed"],"execution_count":1,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"QLX-9_KS2Xer","colab_type":"text"},"source":["## A) TRAIN, DEVELOPMENT AND TEST SPLITS\n","\n","To start with, we are going to work with the same sentiment analysis dataset used in the previous session, i.e., RT-polarity. First, as usual, we need to load the dataset in Python. We are going to load it directly from the internet, but remember from the previous session that you can also load your dataset locally if you wish, or through Google Colab:\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"vR3p8oif2EC6","colab_type":"code","colab":{}},"source":["url_pos=\"http://josecamachocollados.com/rt-polarity.pos.txt\" # Containing all positive reviews, one review per line\n","url_neg=\"http://josecamachocollados.com/rt-polarity.neg.txt\" # Containing all negative reviews, one review per line\n","\n","#Load positive reviews\n","response_pos = requests.get(url_pos)\n","dataset_file_pos = response_pos.text.split(\"\\n\")\n","\n","#Load negative reviews\n","response_neg = requests.get(url_neg)\n","dataset_file_neg = response_neg.text.split(\"\\n\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGhLHgI4gCPW","colab_type":"text"},"source":["Now we are going to split the dataset into training and test splits. First, we need to put together positive and negative reviews into a single list. "]},{"cell_type":"code","metadata":{"id":"Uq35io6Dj7cG","colab_type":"code","colab":{}},"source":["dataset_full=[]\n","for pos_review in dataset_file_pos:\n","  dataset_full.append((pos_review,1))\n","for neg_review in dataset_file_neg:\n","  dataset_full.append((neg_review,0))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sEtWB_f3kRZ7","colab_type":"text"},"source":["**Note:** Remember that positive reviews are going to be labelled as \"1\" and negative reviews as \"0\". To store reviews with their corresponding labels, we have used tuples of the form `(review,label)`."]},{"cell_type":"markdown","metadata":{"id":"VA55oh0Ykc81","colab_type":"text"},"source":["With the full dataset stored in a single list, we are going to split our dataset into training and test, by following a standard 80%/20% distribution. We are going to randomly extract examples from the original dataset, 80% for the training set, and 20% for the test set."]},{"cell_type":"code","metadata":{"id":"9jdN4LaXhm_O","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","import random"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QBlU4Zyehoif","colab_type":"code","colab":{}},"source":["size_dataset_full=len(dataset_full)\n","size_test=int(round(size_dataset_full*0.2,0))\n","\n","list_test_indices=random.sample(range(size_dataset_full), size_test)\n","train_set=[]\n","test_set=[]\n","for i,example in enumerate(dataset_full):\n","  if i in list_test_indices: test_set.append(example)\n","  else: train_set.append(example)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RAke3d5QIAJS","colab_type":"text"},"source":["**Excercise (Optional):**\n","Use the function [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn to split  the original RT-polarity dataset into training and test. More information in this [blog post](https://medium.com/@contactsunny/how-to-split-your-dataset-to-train-and-test-datasets-using-scikit-learn-e7cf6eb5e0d).\n"]},{"cell_type":"markdown","metadata":{"id":"FzK6cEyej3LV","colab_type":"text"},"source":["To double-check that we have split the dataset as we planned to, let's check the final sizes. We are going to also shuffle the examples in each of the splits (using the function `random.shuffle`), as it is recommended in many cases."]},{"cell_type":"code","metadata":{"id":"1JvrD8ACpAbM","colab_type":"code","colab":{}},"source":["random.shuffle(train_set)\n","random.shuffle(test_set)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mnQVSx8GmSk3","colab_type":"code","outputId":"814d0fbd-200a-4e24-831c-70ae8704751d","executionInfo":{"status":"ok","timestamp":1578154207956,"user_tz":0,"elapsed":1158,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print (\"Size dataset full: \"+str(size_dataset_full))\n","print (\"Size training set: \"+str(len(train_set)))\n","print (\"Size test set: \"+str(len(test_set)))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Size dataset full: 10664\n","Size training set: 8531\n","Size test set: 2133\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5IvHkQJ3rbgV","colab_type":"text"},"source":["**Excercise 1:** Given a dataset represented as list with instances (as e.g. our `dataset_full` in the RT-polarity dataset) and the size of the test set (e.g. `0.2`) as input, create a function that split the given dataset in training and test sets of the given size. Check your function with our RT-polarity dataset (i.e. `dataset_full`) and `0.2` as inputs."]},{"cell_type":"code","metadata":{"id":"1pFPy0y5rq-h","colab_type":"code","colab":{}},"source":["def get_train_test_split(dataset_full,ratio):\n","  pre_train_set=[]\n","  pre_test_set=[]\n","  # To complete...\n","\n","  return pre_train_set,pre_test_set\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lPK7iUyZiNMH","colab_type":"text"},"source":["Now we have our dataset split into training and test. However, in many cases we would also need a development set, which can be used to tune our model. To get the development set, we can split the test set in half, and therefore obtain a standard train/dev/test split of 80%/10%/10%."]},{"cell_type":"code","metadata":{"id":"ux5ZOHQ7n3iF","colab_type":"code","colab":{}},"source":["original_size_test=len(test_set)\n","size_dev=int(round(original_size_test*0.5,0))\n","list_dev_indices=random.sample(range(original_size_test), size_dev)\n","new_dev_set=[]\n","new_test_set=[]\n","for i,example in enumerate(test_set):\n","  if i in list_dev_indices: new_dev_set.append(example)\n","  else: new_test_set.append(example)\n","new_train_set=train_set\n","random.shuffle(new_train_set)\n","random.shuffle(new_dev_set)\n","random.shuffle(new_test_set)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NvnP9l9_pLY_","colab_type":"text"},"source":["Our dataset is now split into training, development and test. Let's check some examples from each of the splits."]},{"cell_type":"code","metadata":{"id":"ugo887VzpWQ5","colab_type":"code","outputId":"93dcd70b-5a49-433f-f421-81ac936ef2e5","executionInfo":{"status":"ok","timestamp":1578154214164,"user_tz":0,"elapsed":1021,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["print (\"TRAINING SET\")\n","print (\"Size training set: \"+str(len(new_train_set)))\n","for example in new_train_set[:3]:\n","  print (example)\n","print (\"    \\n-------\\n\")\n","print (\"DEV SET\")\n","print (\"Size development set: \"+str(len(new_dev_set)))\n","for example in new_dev_set[:3]:\n","  print (example)\n","print (\"    \\n-------\\n\")\n","print (\"TEST SET\")\n","print (\"Size test set: \"+str(len(new_test_set)))\n","for example in new_test_set[:3]:\n","  print (example)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["TRAINING SET\n","Size training set: 8531\n","('at some point , all this visual trickery stops being clever and devolves into flashy , vaguely silly overkill . ', 0)\n","('with little visible talent and no energy , colin hanks is in bad need of major acting lessons and maybe a little coffee . ', 0)\n","('there may have been a good film in \" trouble every day , \" but it is not what is on the screen . ', 0)\n","    \n","-------\n","\n","DEV SET\n","Size development set: 1066\n","('unfunny and lacking any sense of commitment to or affection for its characters , the reginald hudlin comedy relies on toilet humor , ethnic slurs . ', 0)\n","('old people will love this movie , and i mean that in the nicest possible way : last orders will touch the heart of anyone old enough to have earned a 50-year friendship . ', 1)\n","('it provides the grand , intelligent entertainment of a superior cast playing smart people amid a compelling plot . ', 1)\n","    \n","-------\n","\n","TEST SET\n","Size test set: 1067\n","(\"nair and writer laura cahill dare to build a movie around some flawed but rather unexceptional women , emerging with a fine character study that's short on plot but rich in the tiny revelations of real life . \", 1)\n","(\"chai's structure and pacing are disconcertingly slack . \", 0)\n","(' . . . about as exciting to watch as two last-place basketball teams playing one another on the final day of the season . ', 0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E7m0tAb_-aTq","colab_type":"text"},"source":["\n","\n","\n","## B) EVALUATION MEASURES\n","\n","---\n","\n","\n","In this section we will evaluate our linear SVM binary classifier (similar to the one we trained in the previous session) in the RT-polarity dataset. We will first train the model on the training set, and then evaluate it in the test set. To this end, we will use functions from the previous sessions, slightly modified to be more general and cover this case.\n"]},{"cell_type":"code","metadata":{"id":"IRlEgUcvIw_f","colab_type":"code","colab":{}},"source":["lemmatizer = nltk.stem.WordNetLemmatizer()\n","stopwords=set(nltk.corpus.stopwords.words('english'))\n","stopwords.add(\".\")\n","stopwords.add(\",\")\n","stopwords.add(\"--\")\n","stopwords.add(\"``\")\n","\n","# Function taken from Session 1\n","def get_list_tokens(string): # Function to retrieve the list of tokens from a string\n","  sentence_split=nltk.tokenize.sent_tokenize(string)\n","  list_tokens=[]\n","  for sentence in sentence_split:\n","    list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n","    for token in list_tokens_sentence:\n","      list_tokens.append(lemmatizer.lemmatize(token).lower())\n","  return list_tokens\n","\n","# Function taken from Session 2\n","def get_vector_text(list_vocab,string):\n","  vector_text=np.zeros(len(list_vocab))\n","  list_tokens_string=get_list_tokens(string)\n","  for i, word in enumerate(list_vocab):\n","    if word in list_tokens_string:\n","      vector_text[i]=list_tokens_string.count(word)\n","  return vector_text\n","\n","\n","# Functions slightly modified from Session 2\n","\n","def get_vocabulary(training_set, num_features): # Function to retrieve vocabulary\n","  dict_word_frequency={}\n","  for instance in training_set:\n","    sentence_tokens=get_list_tokens(instance[0])\n","    for word in sentence_tokens:\n","      if word in stopwords: continue\n","      if word not in dict_word_frequency: dict_word_frequency[word]=1\n","      else: dict_word_frequency[word]+=1\n","  sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:num_features]\n","  vocabulary=[]\n","  for word,frequency in sorted_list:\n","    vocabulary.append(word)\n","  return vocabulary\n","\n","def train_svm_classifier(training_set, vocabulary): # Function for training our svm classifier\n","  X_train=[]\n","  Y_train=[]\n","  for instance in training_set:\n","    vector_instance=get_vector_text(vocabulary,instance[0])\n","    X_train.append(vector_instance)\n","    Y_train.append(instance[1])\n","  # Finally, we train the SVM classifier \n","  svm_clf=sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n","  svm_clf.fit(np.asarray(X_train),np.asarray(Y_train))\n","  return svm_clf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D8Rl3pwSnLtW","colab_type":"code","colab":{}},"source":["vocabulary=get_vocabulary(new_train_set, 1000)  # We use the get_vocabulary function to retrieve the vocabulary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"34V7nF4Dr_8w","colab_type":"code","colab":{}},"source":["svm_clf=train_svm_classifier(new_train_set, vocabulary) # We finally use the function to train our SVM classifier. This can take a while..."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXMERnnPvtZi","colab_type":"text"},"source":["We can now test our model with an example."]},{"cell_type":"code","metadata":{"id":"-FHVHFjHsJgA","colab_type":"code","outputId":"62f61fd0-a246-4da9-9a0c-9cf78b6cdceb","executionInfo":{"status":"ok","timestamp":1578154519403,"user_tz":0,"elapsed":992,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["print (svm_clf.predict([get_vector_text(vocabulary,\"Fascinating!\")]))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vln_3gb4zV_y","colab_type":"text"},"source":["Once we have trained our SVM classifier, we can test our model in the training set. To that end, we need to convert the training set in two lists (`X_test` and `Y_test`), similarly as we did with the training set."]},{"cell_type":"code","metadata":{"id":"QwJSvwL4v8eM","colab_type":"code","colab":{}},"source":["X_test=[]\n","Y_test=[]\n","for instance in new_test_set:\n","  vector_instance=get_vector_text(vocabulary,instance[0])\n","  X_test.append(vector_instance)\n","  Y_test.append(instance[1])\n","X_test=np.asarray(X_test)\n","Y_test_gold=np.asarray(Y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5OPXPxYBwhv0","colab_type":"text"},"source":["We referred to the labels in the test set as `Y_test_gold` to distinguish them from our predictions (*gold standard* makes reference to the ground truth, which are the labels that are known to be correct). Now we can test our model in the test set using `predict` (to obtain the predictions of our model) and `classification_report` (to get the results) from sklearn."]},{"cell_type":"code","metadata":{"id":"Nko4wlsWw0Ov","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c9owZU57x8q4","colab_type":"code","colab":{}},"source":["Y_text_predictions=svm_clf.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JY7G9Rhaw2fh","colab_type":"code","outputId":"2d6f165a-ef98-4bec-edc2-d6fc7db9926c","executionInfo":{"status":"ok","timestamp":1578085920728,"user_tz":0,"elapsed":592,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["print(classification_report(Y_test_gold, Y_text_predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.71      0.72      0.72       544\n","           1       0.71      0.69      0.70       523\n","\n","    accuracy                           0.71      1067\n","   macro avg       0.71      0.71      0.71      1067\n","weighted avg       0.71      0.71      0.71      1067\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tZ4WHJugys5S","colab_type":"text"},"source":["We can also get the individual accuracy and macro-average precision, recall and F-score individually."]},{"cell_type":"code","metadata":{"id":"NU-Ls__RzAsO","colab_type":"code","colab":{}},"source":["from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z_5_vsFBzJQw","colab_type":"code","outputId":"28a2366a-e483-4bfb-ea0a-c97899fd1df3","executionInfo":{"status":"ok","timestamp":1578154541143,"user_tz":0,"elapsed":671,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["precision=precision_score(Y_test_gold, Y_text_predictions, average='macro')\n","recall=recall_score(Y_test_gold, Y_text_predictions, average='macro')\n","f1=f1_score(Y_test_gold, Y_text_predictions, average='macro')\n","accuracy=accuracy_score(Y_test_gold, Y_text_predictions)\n","\n","print (\"Precision: \"+str(round(precision,3)))\n","print (\"Recall: \"+str(round(recall,3)))\n","print (\"F1-Score: \"+str(round(f1,3)))\n","print (\"Accuracy: \"+str(round(accuracy,3)))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Precision: 0.672\n","Recall: 0.672\n","F1-Score: 0.672\n","Accuracy: 0.672\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"N60XYawkVYx0","colab_type":"text"},"source":["To understand better the source of the error made by the model, we can get a confusion matrix (see [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) for more details on confusion matrices in sklearn)."]},{"cell_type":"code","metadata":{"id":"9ANdqEL5VjX8","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"c_2-6vz6Vkq9","colab_type":"code","outputId":"8835fa4a-3c5d-4aa2-8ca9-b33cfbefcd7d","executionInfo":{"status":"ok","timestamp":1578154547539,"user_tz":0,"elapsed":978,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["print (confusion_matrix(Y_test_gold, Y_text_predictions))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[[376 160]\n"," [190 341]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eyUr1Beq0v3a","colab_type":"text"},"source":["Depending on your split, your results may vary a bit. As you may have realized, we have not made use of our **development set**! Let's try to tune our model in the development set, as that can help improve our model overall! In the development set we can tune anything we want, from the model to use, to the parameters or features. In our case, let's try to tune the number of features in the test set. We can try with less than 1000 features, which was our vocabulary. For example, let's try with `num_features=250`, `num_features=500`, `num_features=750` and `num_features=1000`. We can then tune our model with respect to these features and optimize it for accuracy."]},{"cell_type":"code","metadata":{"id":"itSiK2uN16l-","colab_type":"code","outputId":"11112150-e029-4c06-881b-620d3a0eb2dd","executionInfo":{"status":"ok","timestamp":1578154799057,"user_tz":0,"elapsed":251030,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["# We first get the gold standard labels from the development set\n","\n","Y_dev=[]\n","for instance in new_dev_set:\n","  Y_dev.append(instance[1])\n","Y_dev_gold=np.asarray(Y_dev)\n","\n","# Now we can train our three models with the different number of features, and test each of them in the dev set\n","\n","list_num_features=[250,500,750,1000]\n","best_accuracy_dev=0.0\n","for num_features in list_num_features:\n","  # First, we get the vocabulary from the training set and train our svm classifier\n","  vocabulary=get_vocabulary(new_train_set, num_features)  \n","  svm_clf=train_svm_classifier(new_train_set, vocabulary)\n","  # Then, we transform our dev set into vectors and make the prediction on this set\n","  X_dev=[]\n","  for instance in new_dev_set:\n","    vector_instance=get_vector_text(vocabulary,instance[0])\n","    X_dev.append(vector_instance)\n","  X_dev=np.asarray(X_dev)\n","  Y_dev_predictions=svm_clf.predict(X_dev)\n","  # Finally, we get the accuracy results of the classifier\n","  accuracy_dev=accuracy_score(Y_dev_gold, Y_dev_predictions)\n","  print (\"Accuracy with \"+str(num_features)+\": \"+str(round(accuracy_dev,3)))\n","  if accuracy_dev>=best_accuracy_dev:\n","    best_accuracy_dev=accuracy_dev\n","    best_num_features=num_features\n","    best_vocabulary=vocabulary\n","    best_svm_clf=svm_clf\n","print (\"\\n Best accuracy overall in the dev set is \"+str(round(best_accuracy_dev,3))+\" with \"+str(best_num_features)+\" features.\")"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Accuracy with 250: 0.643\n","Accuracy with 500: 0.669\n","Accuracy with 750: 0.686\n","Accuracy with 1000: 0.696\n","\n"," Best accuracy overall in the dev set is 0.696 with 1000 features.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vd2B3ABz860y","colab_type":"text"},"source":["Let's now check the performance (accuracy) of the best model in the test set.\n","\n","**Note:** Not always the best model in the development set leads to the best results on the test set."]},{"cell_type":"code","metadata":{"id":"Kjz-ZXa48_89","colab_type":"code","outputId":"397a119a-fde0-4bff-d53e-7e6fbc87ec4c","executionInfo":{"status":"ok","timestamp":1578155405390,"user_tz":0,"elapsed":8842,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["X_test=[]\n","Y_test=[]\n","for instance in new_test_set:\n","  vector_instance=get_vector_text(best_vocabulary,instance[0])\n","  X_test.append(vector_instance)\n","  Y_test.append(instance[1])\n","best_X_test=np.asarray(X_test)\n","Y_test_gold=np.asarray(Y_test)\n","\n","best_Y_text_predictions=best_svm_clf.predict(best_X_test)\n","print(classification_report(Y_test_gold, best_Y_text_predictions))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.66      0.70      0.68       536\n","           1       0.68      0.64      0.66       531\n","\n","    accuracy                           0.67      1067\n","   macro avg       0.67      0.67      0.67      1067\n","weighted avg       0.67      0.67      0.67      1067\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FFdRoZAr2iTn","colab_type":"text"},"source":["**Note:** Please note that we have made use of the test set only once. We haven't evaluated more than one model in the test set. This is important, as any tuning should be done in the test set if we want our method to generalize well and comparable to other models. If we evaluate many times on the test set, we risk overfitting our model to the test set."]},{"cell_type":"markdown","metadata":{"id":"DXuBJC7b9hW-","colab_type":"text"},"source":["**Exercise 2:** Tune the same classifier, this time with `num_features=100`, `num_features=500` and `num_features=1000` and optimize it for macro-average F1-score, instead of accuracy. Test the best-performing classifier in the development set (in terms of F1-score) on the test."]},{"cell_type":"code","metadata":{"id":"0EDb9dm21dfA","colab_type":"code","outputId":"0291c953-bd5b-4467-c878-a2e68aae6989","executionInfo":{"status":"error","timestamp":1578084459544,"user_tz":0,"elapsed":150107,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":408}},"source":["list_num_features=[100,500,1000]\n","best_f1_dev=0.0\n","for num_features in list_num_features:\n","  vocabulary=get_vocabulary(new_train_set, num_features)  \n","  svm_clf=train_svm_classifier(new_train_set, vocabulary)\n","  X_dev=[]\n","  for instance in new_dev_set:\n","    vector_instance=get_vector_text(vocabulary,instance[0])\n","    X_dev.append(vector_instance)\n","  X_dev=np.asarray(X_dev)\n","  Y_dev_predictions=svm_clf.predict(X_dev)\n","  f1_dev=f1_score(Y_dev_gold, Y_dev_predictions, average='macro')\n","  print (\"F1-Score with \"+str(num_features)+\": \"+str(round(f1_dev,3)))\n","  if f1_dev>=best_f1_dev:\n","    best_f1_dev=f1_dev\n","    best_num_features=num_features\n","    best_vocabulary=vocabulary\n","    best_svm_clf=svm_clf\n","print (\"\\nBest F-Score overall in the dev set is \"+str(round(best_f1_dev,3))+\" with \"+str(best_num_features)+\" features.\")\n","# Now we test the best classifier (in the dev set) on the test set\n","X_test=[]\n","Y_test=[]\n","for instance in new_test_set:\n","  vector_instance=get_vector_text(best_vocabulary,instance[0])\n","  X_test.append(vector_instance)\n","  Y_test.append(instance[1])\n","Y_test_gold=np.asarray(Y_test)\n","best_X_test=np.asarray(X_test)\n","best_Y_text_predictions=best_svm_clf.predict(best_X_test)\n","print(\"\\nPerformance in the test set\\n\")\n","print(classification_report(Y_test_gold, best_Y_text_predictions))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["F1-Score with 100: 0.603\n","F1-Score with 500: 0.694\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-8c240336d0d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_num_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0msvm_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_svm_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mX_dev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnew_dev_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-19-4d77ed477efe>\u001b[0m in \u001b[0;36mtrain_svm_classifier\u001b[0;34m(training_set, vocabulary)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;31m# Finally, we train the SVM classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0msvm_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"linear\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m   \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"16K6wkXq9wS-","colab_type":"text"},"source":["**Exercise (optional):** Think about other elements to tune in the development set. For example, parameters in the SVM (e.g., smaller values of the [C regularization parameter](https://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel), more information about the parameters of the SVM [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)), other vocabulary sizes or features, feature selection methods, etc."]},{"cell_type":"markdown","metadata":{"id":"CYlpPJlz-NxK","colab_type":"text"},"source":["## C) CROSS-VALIDATION\n","\n","In addition to the usual train, development and test splits, there is an alternative that it's called cross-validation. With this technique we use a single set with all our examples, and create several different train/test splits (or train/dev/test). This has the advantage of testing on a wider range of examples (useful especially when your dataset is not very large) but the disadvantage of being computationally more expensive and not easily reproducible.\n","\n","We are going to start with 5-fold validation, i.e., the dataset is split into five parts, which will be used as five different test sets. Let's evaluate our model with 500 features on the full RT-polarity dataset using 5-fold cross-validation.\n"," "]},{"cell_type":"code","metadata":{"id":"X0-MbK7lJYn8","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import KFold"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wvBT_YX6GzW2","colab_type":"code","outputId":"13a10be3-8e38-4196-aea7-364592de3862","executionInfo":{"status":"ok","timestamp":1578156042577,"user_tz":0,"elapsed":289044,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["kf = KFold(n_splits=5)\n","random.shuffle(dataset_full)\n","kf.get_n_splits(dataset_full)\n","accuracy_total=0.0\n","for train_index, test_index in kf.split(dataset_full):\n","  train_set_fold=[]\n","  test_set_fold=[]\n","  for i,instance in enumerate(dataset_full):\n","    if i in train_index:\n","      train_set_fold.append(instance)\n","    else:\n","      test_set_fold.append(instance)\n","  vocabulary_fold=get_vocabulary(train_set_fold, 500)\n","  svm_clf_fold=train_svm_classifier(train_set_fold, vocabulary_fold)\n","  X_test_fold=[]\n","  Y_test_fold=[]\n","  for instance in test_set_fold:\n","    vector_instance=get_vector_text(vocabulary_fold,instance[0])\n","    X_test_fold.append(vector_instance)\n","    Y_test_fold.append(instance[1])\n","  Y_test_fold_gold=np.asarray(Y_test_fold)\n","  X_test_fold=np.asarray(X_test_fold)\n","  Y_test_predictions_fold=svm_clf_fold.predict(X_test_fold)\n","  accuracy_fold=accuracy_score(Y_test_fold_gold, Y_test_predictions_fold)\n","  accuracy_total+=accuracy_fold\n","  print (\"Fold completed.\")\n","average_accuracy=accuracy_total/5\n","print (\"\\nAverage Accuracy: \"+str(round(average_accuracy,3)))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Fold completed.\n","Fold completed.\n","Fold completed.\n","Fold completed.\n","Fold completed.\n","\n","Average Accuracy: 0.679\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7OhkMwSdMsbS","colab_type":"text"},"source":["**Note:** Sklearn contains the [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html) function, which is very convinent to evaluate our model in a cross-validation setting. However, we cannot use this function when the features depend on the dataset itself, as it is our case in the RT-polarity dataset (the vocabulary depends on the training set)."]},{"cell_type":"markdown","metadata":{"id":"gRP5RfSyN80Q","colab_type":"text"},"source":["**Exercise (optional):** Use the `cross_val_score` function from sklearn to evaluate an SVM classifier from the Diabetes dataset (Session 2) using 10-fold cross-validation."]},{"cell_type":"markdown","metadata":{"id":"IENomO9qGyeT","colab_type":"text"},"source":["**Exercise 3:** Use 3-fold cross-validation to evaluate the SVM classifier with 1000 features (instead of 500). Print the accuracy of the classifier in every of the three folds, and the overall accuracy at the end."]},{"cell_type":"code","metadata":{"id":"Zp1pR4AWl_fK","colab_type":"code","outputId":"2d5d76b2-be6f-45a9-f639-b0fd0da72248","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1578157888925,"user_tz":0,"elapsed":1268473,"user":{"displayName":"shuai han","photoUrl":"","userId":"17730290437654356068"}}},"source":["from sklearn.model_selection import KFold\n","num_folds=10\n","num_features=1000\n","kf = KFold(n_splits=num_folds)\n","random.shuffle(dataset_full)\n","kf.get_n_splits(dataset_full)\n","j_fold=0\n","accuracy_total=0.0\n","for train_index, test_index in kf.split(dataset_full):\n","  j_fold+=1\n","  train_set_fold=[]\n","  test_set_fold=[]\n","  for i,instance in enumerate(dataset_full):\n","    if i in train_index:\n","      train_set_fold.append(instance)\n","    else:\n","      test_set_fold.append(instance)\n","  vocabulary_fold=get_vocabulary(train_set_fold, num_features)\n","  svm_clf_fold=train_svm_classifier(train_set_fold, vocabulary_fold)\n","  X_test_fold=[]\n","  Y_test_fold=[]\n","  for instance in test_set_fold:\n","    vector_instance=get_vector_text(vocabulary_fold,instance[0])\n","    X_test_fold.append(vector_instance)\n","    Y_test_fold.append(instance[1])\n","  Y_test_fold_gold=np.asarray(Y_test_fold)\n","  X_test_fold=np.asarray(X_test_fold)\n","  Y_test_predictions_fold=svm_clf_fold.predict(X_test_fold)\n","  accuracy_fold=accuracy_score(Y_test_fold_gold, Y_test_predictions_fold)\n","  accuracy_total+=accuracy_fold\n","  print (\"Fold \"+str(j_fold)+\"/\"+str(num_folds)+\" completed. Accuracy: \"+str(accuracy_fold))\n","  print(classification_report(Y_test_fold_gold, Y_test_predictions_fold))\n","  \n","average_accuracy=accuracy_total/num_folds\n","print (\"\\nAverage Accuracy: \"+str(round(average_accuracy,3)))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Fold 1/10 completed. Accuracy: 0.7075913776944704\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.73      0.72       538\n","           1       0.71      0.68      0.70       529\n","\n","    accuracy                           0.71      1067\n","   macro avg       0.71      0.71      0.71      1067\n","weighted avg       0.71      0.71      0.71      1067\n","\n","Fold 2/10 completed. Accuracy: 0.7244611059044048\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.74      0.72       510\n","           1       0.75      0.71      0.73       557\n","\n","    accuracy                           0.72      1067\n","   macro avg       0.72      0.72      0.72      1067\n","weighted avg       0.73      0.72      0.72      1067\n","\n","Fold 3/10 completed. Accuracy: 0.6991565135895033\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.73      0.71       548\n","           1       0.70      0.67      0.68       519\n","\n","    accuracy                           0.70      1067\n","   macro avg       0.70      0.70      0.70      1067\n","weighted avg       0.70      0.70      0.70      1067\n","\n","Fold 4/10 completed. Accuracy: 0.7141518275538894\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.73      0.72       541\n","           1       0.72      0.69      0.71       526\n","\n","    accuracy                           0.71      1067\n","   macro avg       0.71      0.71      0.71      1067\n","weighted avg       0.71      0.71      0.71      1067\n","\n","Fold 5/10 completed. Accuracy: 0.701688555347092\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.73      0.72       560\n","           1       0.69      0.67      0.68       506\n","\n","    accuracy                           0.70      1066\n","   macro avg       0.70      0.70      0.70      1066\n","weighted avg       0.70      0.70      0.70      1066\n","\n","Fold 6/10 completed. Accuracy: 0.6969981238273921\n","              precision    recall  f1-score   support\n","\n","           0       0.69      0.72      0.71       536\n","           1       0.70      0.67      0.69       530\n","\n","    accuracy                           0.70      1066\n","   macro avg       0.70      0.70      0.70      1066\n","weighted avg       0.70      0.70      0.70      1066\n","\n","Fold 7/10 completed. Accuracy: 0.7091932457786116\n","              precision    recall  f1-score   support\n","\n","           0       0.68      0.73      0.71       511\n","           1       0.74      0.69      0.71       555\n","\n","    accuracy                           0.71      1066\n","   macro avg       0.71      0.71      0.71      1066\n","weighted avg       0.71      0.71      0.71      1066\n","\n","Fold 8/10 completed. Accuracy: 0.701688555347092\n","              precision    recall  f1-score   support\n","\n","           0       0.70      0.73      0.72       550\n","           1       0.70      0.67      0.68       516\n","\n","    accuracy                           0.70      1066\n","   macro avg       0.70      0.70      0.70      1066\n","weighted avg       0.70      0.70      0.70      1066\n","\n","Fold 9/10 completed. Accuracy: 0.7363977485928705\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.76      0.74       535\n","           1       0.75      0.71      0.73       531\n","\n","    accuracy                           0.74      1066\n","   macro avg       0.74      0.74      0.74      1066\n","weighted avg       0.74      0.74      0.74      1066\n","\n","Fold 10/10 completed. Accuracy: 0.6960600375234521\n","              precision    recall  f1-score   support\n","\n","           0       0.66      0.74      0.70       503\n","           1       0.74      0.66      0.70       563\n","\n","    accuracy                           0.70      1066\n","   macro avg       0.70      0.70      0.70      1066\n","weighted avg       0.70      0.70      0.70      1066\n","\n","\n","Average Accuracy: 0.709\n"],"name":"stdout"}]}]}